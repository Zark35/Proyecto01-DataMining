import requests
import pandas as pd
import json
import datetime
import time
import random
from sqlalchemy import create_engine
from mage_ai.data_preparation.shared.secrets import get_secret_value

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


def refresh_access_token():
    import base64

    client_id = get_secret_value('qb_client_id')
    client_secret = get_secret_value('qb_client_secret')
    refresh_token = get_secret_value('qb_refresh_token')

    url = "https://oauth.platform.intuit.com/oauth2/v1/tokens/bearer"

    creds = f"{client_id}:{client_secret}".encode("utf-8")
    b64_creds = base64.b64encode(creds).decode("utf-8")

    headers = {
        "Accept": "application/json",
        "Content-Type": "application/x-www-form-urlencoded",
        "Authorization": f"Basic {b64_creds}"
    }

    data = {"grant_type": "refresh_token", "refresh_token": refresh_token}

    response = requests.post(url, headers=headers, data=data, timeout=30)
    response.raise_for_status()
    tokens = response.json()
    return tokens['access_token']
    

""" def _fetch_qb_data(realm_id, access_token, query, base_url, minor_version):
    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json',
        'Content-Type': 'text/plain'
    }
    params = {"query": query, "minorversion": minor_version}
    url = f"{base_url.rstrip('/')}/v3/company/{realm_id}/query"
    response = requests.get(url, headers=headers, params=params, timeout=60)
    response.raise_for_status()
    return response.json()
"""
def _fetch_qb_data(realm_id, access_token, query, base_url, minor_version, page_size=1000, max_retries=5):
    """
    Llama a la API de QuickBooks con paginaci√≥n y backoff exponencial.
    
    - Usa STARTPOSITION y MAXRESULTS para recorrer todas las p√°ginas.
    - Reintenta en caso de error con backoff exponencial.
    - Devuelve la lista completa de registros.
    """
    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json',
        'Content-Type': 'text/plain'
    }

    all_records = []
    start_position = 1
    has_more = True
    page = 1

    while has_more:
        paged_query = f"{query} STARTPOSITION {start_position} MAXRESULTS {page_size}"
        params = {
            "query": paged_query,
            "minorversion": minor_version
        }
        url = f"{base_url.rstrip('/')}/v3/company/{realm_id}/query"

        for intento in range(max_retries):
            try:
                response = requests.get(url, headers=headers, params=params, timeout=60)
                response.raise_for_status()
                data = response.json()

                # Extraer registros de la respuesta
                records = data.get('QueryResponse', {}).get('Invoice', [])
                all_records.extend(records)

                print(f"‚úÖ P√°gina {page}: {len(records)} registros obtenidos (posici√≥n inicial {start_position})")

                # Si recibimos menos registros que el page_size ‚Üí no hay m√°s p√°ginas
                has_more = len(records) == page_size
                break

            except requests.exceptions.RequestException as e:
                espera = (2 ** intento) + random.uniform(0, 1)
                print(f"‚ö†Ô∏è Error en la p√°gina {page} ({e}). Reintentando en {espera:.2f}s...")
                time.sleep(espera)

                if intento == max_retries - 1:
                    print("‚ùå Fall√≥ despu√©s de m√∫ltiples intentos, abortando este tramo.")
                    has_more = False
                    break

        # Avanzar a la siguiente p√°gina
        start_position += page_size
        page += 1

    print(f"üìä Total de registros extra√≠dos: {len(all_records)}")
    return all_records


def _save_raw_json_to_postgres(records: list, table_name: str):
    user = get_secret_value('pg_user')
    password = get_secret_value('pg_password')
    host = get_secret_value('pg_host')
    port = get_secret_value('pg_port')
    db = get_secret_value('pg_db')

    url_conn = f'postgresql://{user}:{password}@{host}:{port}/{db}'
    engine = create_engine(url_conn)

    df = pd.DataFrame([{'data': json.dumps(record)} for record in records])
    df.to_sql(table_name, con=engine, if_exists='append', index=False)


"""
@data_loader
def load_data_from_api(*args, **kwargs):
    
    #Pipeline con segmentaci√≥n:
    # Usa fecha_inicio y fecha_fin (ISO: YYYY-MM-DD).
    # Divide en chunks diarios (puedes cambiar a semanales).
    # Guarda los datos crudos en Postgres.

    realm_id = get_secret_value('qb_realm_id')
    access_token = refresh_access_token()
    minor_version = 75
    base_url = 'https://sandbox-quickbooks.api.intuit.com'

    # Parametros recibidos
    fecha_inicio = kwargs.get('fecha_inicio', '2025-08-01')
    fecha_fin = kwargs.get('fecha_fin', '2025-08-07')

    start_date = datetime.date.fromisoformat(fecha_inicio)
    end_date = datetime.date.fromisoformat(fecha_fin)

    results_summary = []

    current_date = start_date
    while current_date <= end_date:
        chunk_start = current_date
        chunk_end = min(chunk_start + datetime.timedelta(days=1), end_date)

        query = f"select * from Invoice where TxnDate >= '{chunk_start}' and TxnDate <= '{chunk_end}'"

        print(f"Procesando rango: {chunk_start} ‚Üí {chunk_end}")
        start_time = time.time()

        try:
            data = _fetch_qb_data(realm_id, access_token, query, base_url, minor_version)
            records = data.get('QueryResponse', {}).get('Invoice', [])

            if records:
                _save_raw_json_to_postgres(records, 'raw_invoices')

            elapsed = time.time() - start_time
            results_summary.append({
                "fecha_inicio": str(chunk_start),
                "fecha_fin": str(chunk_end),
                "filas": len(records),
                "duracion_seg": round(elapsed, 2),
            })

            print(f"‚úÖ {len(records)} filas insertadas en {elapsed:.2f} seg.")

        except Exception as e:
            print(f"‚ùå Error en el rango {chunk_start} ‚Üí {chunk_end}: {e}")

        current_date = chunk_end + datetime.timedelta(days=1)

    return {"chunks": results_summary}
"""
@data_loader
def load_data_from_api(*args, **kwargs):
    """
    Pipeline con segmentaci√≥n y paginaci√≥n.
    - Usa fecha_inicio y fecha_fin (ISO).
    - Divide en chunks diarios.
    - Llama a _fetch_qb_data que devuelve una lista de registros.
    - Guarda en Postgres en formato raw JSON.
    """
    import datetime, time

    realm_id = get_secret_value('qb_realm_id')
    access_token = refresh_access_token()
    minor_version = 75
    base_url = 'https://sandbox-quickbooks.api.intuit.com'

    fecha_inicio = kwargs.get('fecha_inicio', '2025-08-01')
    fecha_fin = kwargs.get('fecha_fin', '2025-08-07')

    start_date = datetime.date.fromisoformat(fecha_inicio)
    end_date = datetime.date.fromisoformat(fecha_fin)

    results_summary = []

    current_date = start_date
    while current_date <= end_date:
        chunk_start = current_date
        chunk_end = min(chunk_start + datetime.timedelta(days=1), end_date)

        query = f"select * from Invoice where TxnDate >= '{chunk_start}' and TxnDate <= '{chunk_end}'"

        print(f"\nProcesando rango: {chunk_start} ‚Üí {chunk_end}")
        start_time = time.time()

        try:
            # Ahora _fetch_qb_data devuelve directamente una lista de registros
            records = _fetch_qb_data(realm_id, access_token, query, base_url, minor_version)

            if records:
                _save_raw_json_to_postgres(records, 'raw_invoices')

            elapsed = time.time() - start_time
            results_summary.append({
                "fecha_inicio": str(chunk_start),
                "fecha_fin": str(chunk_end),
                "filas": len(records),
                "duracion_seg": round(elapsed, 2),
            })

            print(f"‚úÖ {len(records)} filas insertadas en {elapsed:.2f} seg.")

        except Exception as e:
            print(f"‚ùå Error en el rango {chunk_start} ‚Üí {chunk_end}: {e}")

        current_date = chunk_end + datetime.timedelta(days=1)

    return {"chunks": results_summary}


@test
def test_output(output, *args) -> None:
    assert "chunks" in output, "El bloque no devolvi√≥ los resultados esperados"
    print("Resumen de chunks procesados:")
    for chunk in output["chunks"]:
        print(chunk)
